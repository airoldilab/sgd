% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/sgd.R
\name{sgd}
\alias{sgd}
\alias{sgd.big.matrix}
\alias{sgd.formula}
\alias{sgd.function}
\alias{sgd.matrix}
\title{Stochastic gradient descent}
\usage{
sgd(x, ...)

\method{sgd}{formula}(formula, data, model, model.control = list(),
  sgd.control = list(...), ...)

\method{sgd}{function}(fn, gr = NULL, x, y, nparams,
  sgd.control = list(...), ...)

\method{sgd}{matrix}(x, y, model, model.control = list(),
  sgd.control = list(...), ...)

\method{sgd}{big.matrix}(x, y, model, model.control = list(),
  sgd.control = list(...), ...)
}
\arguments{
\item{x,y}{a design matrix and the respective vector of outcomes.}

\item{formula}{an object of class \code{"\link{formula}"} (or one that can be
coerced to that class): a symbolic description of the model to be fitted.
The details can be found in \code{"\link{glm}"}.}

\item{data}{an optional data frame, list or environment (or object coercible
by \code{\link[base]{as.data.frame}} to a data frame) containing the
variables in the model. If not found in data, the variables are taken from
environment(formula), typically the environment from which glm is called.}

\item{model}{character specifying the model to be used: \code{"lm"} (linear
model), \code{"glm"} (generalized linear model), \code{"cox"} (Cox
proportional hazards model), \code{"ee"} (estimating equation). See
\sQuote{Details}.}

\item{model.control}{a list of parameters for controlling the model.
\describe{
  \item{\code{family} (\code{"glm"})}{a description of the error distribution and
    link function to be used in the model. This can be a character string
    naming a family function, a family function or the result of a call to
    a family function. (See \code{\link[stats]{family}} for details of
    family functions.)}
  \item{\code{rank} (\code{"glm"})}{logical. Should the rank of the design matrix
    be checked?}
  \item{\code{fn} (\code{"ee"})}{a function \eqn{g(\theta,x)} which returns a
    \eqn{k}-vector corresponding to the \eqn{k} moment conditions. It is a
    required argument if \code{gr} not specified.}
  \item{\code{gr} (\code{"ee"})}{a function to return the gradient. If
    unspecified, a finite-difference approximation will be used.}
  \item{\code{nparams} (\code{"ee"})}{number of model parameters. This is
    automatically determined for other models.}
  \item{\code{type} (\code{"ee"})}{character specifying the generalized method of
    moments procedure: \code{"twostep"} (Hansen, 1982), \code{"iterative"}
    (Hansen et al., 1996). Defaults to \code{"iterative"}.}
  \item{\code{wmatrix} (\code{"ee"})}{weighting matrix to be used in the loss
    function. Defaults to the identity matrix.}
  \item{\code{lambda1}}{L1 regularization parameter. Default is 0.}
  \item{\code{lambda2}}{L2 regularization parameter. Default is 0.}
}}

\item{sgd.control}{an optional list of parameters for controlling the estimation.
\describe{
  \item{\code{method}}{character specifying the method to be used: \code{"sgd"},
    \code{"implicit"}, \code{"asgd"}, \code{"ai-sgd"}, \code{"momentum"},
    \code{"nesterov"}. Default is \code{"ai-sgd"}. See \sQuote{Details}.}
  \item{\code{lr}}{character specifying the learning rate to be used:
    \code{"one-dim"}, \code{"one-dim-eigen"}, \code{"d-dim"},
    \code{"adagrad"}, \code{"rmsprop"}. Default is \code{"one-dim"}.
    See \sQuote{Details}.}
  \item{\code{lr.control}}{vector of scalar hyperparameters one can
    set dependent on the learning rate. For hyperparameters aimed
    to be left as default, specify \code{NA} in the corresponding
    entries. See \sQuote{Details}.}
  \item{\code{start}}{starting values for the parameter estimates. Default is
    random initialization around zero.}
  \item{\code{size}}{number of SGD estimates to store for diagnostic purposes
    (distributed log-uniformly over total number of iterations)}
  \item{\code{reltol}}{relative convergence tolerance. The algorithm stops
    if it is unable to change the relative mean squared difference in the
    parameters by more than the amount. Default is \code{1e-05}.}
  \item{\code{npasses}}{the maximum number of passes over the data. Default
    is 3.}
  \item{\code{pass}}{logical. Should \code{tol} be ignored and run the
   algorithm for all of \code{npasses}?}
  \item{\code{verbose}}{logical. Should the algorithm print progress?}
}}

\item{fn}{a function \eqn{f(theta, x)} of parameters and data, which outputs
a real number to be minimized.}

\item{gr}{a function to return the gradient. If it is \code{NULL}, a
finite-difference approximation will be used.}

\item{\dots}{arguments to be used to form the default \code{sgd.control}
arguments if it is not supplied directly.}
}
\value{
An object of class \code{"sgd"}, which is a list containing the following
components:
\item{model}{name of the model}
\item{coefficients}{a named vector of coefficients}
\item{converged}{logical. Was the algorithm judged to have converged?}
\item{estimates}{estimates from algorithm stored at each iteration
    specified in \code{pos}}
\item{pos}{vector of indices specifying the iteration number each estimate
    was stored for}
\item{times}{vector of times in seconds it took to complete the number of
    iterations specified in \code{pos}}
\item{model.out}{a list of model-specific output attributes}
}
\description{
Run stochastic gradient descent in order to optimize the induced loss
function given a model and data.
}
\details{
Models:
The Cox model assumes that the survival data is ordered when passed
in, i.e., such that the risk set of an observation i is all data points after
it.

Methods:
\describe{
  \item{\code{sgd}}{stochastic gradient descent (Robbins and Monro, 1951)}
  \item{\code{implicit}}{implicit stochastic gradient descent (Toulis et al.,
    2014)}
  \item{\code{asgd}}{stochastic gradient with averaging (Polyak and Juditsky,
    1992)}
  \item{\code{ai-sgd}}{implicit stochastic gradient with averaging (Toulis et
    al., 2015)}
  \item{\code{momentum}}{"classical" momentum (Polyak, 1964)}
  \item{\code{nesterov}}{Nesterov's accelerated gradient (Nesterov, 1983)}
}

Learning rates and hyperparameters:
\describe{
  \item{\code{one-dim}}{scalar value prescribed in Xu (2011) as
    \deqn{a_n = scale * gamma/(1 + alpha*gamma*n)^(-c)}
    where the defaults are
    \code{lr_control = (scale=1, gamma=1, alpha=1, c)}
    where \code{c} is \code{1} if implemented without averaging,
    \code{2/3} if with averaging}
  \item{\code{one-dim-eigen}}{diagonal matrix
    \code{lr_control = NULL}}
  \item{\code{d-dim}}{diagonal matrix
    \code{lr_control = (epsilon=1e-6)}}
  \item{\code{adagrad}}{diagonal matrix prescribed in Duchi et al. (2011) as
    \code{lr_control = (eta=1, epsilon=1e-6)}}
  \item{\code{rmsprop}}{diagonal matrix prescribed in Tieleman and Hinton
    (2012) as
    \code{lr_control = (eta=1, gamma=0.9, epsilon=1e-6)}}
}
}
\examples{
## Dobson (1990, p.93): Randomized Controlled Trial
counts <- c(18, 17, 15, 20, 10, 20, 25, 13, 12)
outcome <- gl(3, 1, 9)
treatment <- gl(3, 3)
print(d.AD <- data.frame(treatment, outcome, counts))
sgd.D93 <- sgd(counts ~ outcome + treatment, model="glm",
               model.control=list(family = poisson()))
sgd.D93
}
\author{
Dustin Tran, Tian Lan, Panos Toulis, Ye Kuang, Edoardo Airoldi
}
\references{
John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for
online learning and stochastic optimization. \emph{Journal of Machine
Learning Research}, 12:2121-2159, 2011.

Yurii Nesterov. A method for solving a convex programming problem with
convergence rate \eqn{O(1/k^2)}. \emph{Soviet Mathematics Doklady},
27(2):372-376, 1983.

Boris T. Polyak. Some methods of speeding up the convergence of iteration
methods. \emph{USSR Computational Mathematics and Mathematical Physics},
4(5):1â€“17, 1964.

Boris T. Polyak and Anatoli B. Juditsky. Acceleration of stochastic
approximation by averaging. \emph{SIAM Journal on Control and Optimization},
30(4):838-855, 1992.

Herbert Robbins and Sutton Monro. A stochastic approximation method.
\emph{The Annals of Mathematical Statistics}, pp. 400-407, 1951.

Panos Toulis, Jason Rennie, and Edoardo M. Airoldi, "Statistical analysis of
stochastic gradient methods for generalized linear models", In
\emph{Proceedings of the 31st International Conference on Machine Learning},
2014.

Panos Toulis, Dustin Tran, and Edoardo M. Airoldi, "Stability and optimality
in stochastic gradient descent", arXiv preprint arXiv:1505.02417, 2015.

Wei Xu. Towards optimal one pass large scale learning with averaged
stochastic gradient descent. arXiv preprint arXiv:1107.2490, 2011.
}

